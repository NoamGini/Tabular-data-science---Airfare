{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae45b29-d84e-4e34-ae77-4ec2a583d846",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Attempting to fit house prices, using the [Filght fare](https://www.kaggle.com/datasets/yashdharme36/airfare-ml-predicting-flight-fares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac7f92-02dd-41d4-a81a-2e7e53e29f92",
   "metadata": {},
   "source": [
    "Imports of relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2865dd-d9d0-437d-bc7f-a581b0bb6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Machine learning library\n",
    "import sklearn\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfe62e-5e34-400b-b0c5-829aca3bbb89",
   "metadata": {},
   "source": [
    "1. Introducing the House prices dataset -- Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b6e52-a37b-4621-bf05-ed31dfe9829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.read_csv(\"./data/data_airfare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ca59e-1a86-4380-9efb-dea46a5268e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = dtf.dtypes[(dtf.dtypes==\"float64\") | (dtf.dtypes==\"int64\")].index.tolist()\n",
    "categorical_columns = [c for c in dtf.columns if c not in numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcce0f-7c49-4373-8974-0bc3f090877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Date_of_journey\",\"Journey_day\",\"Airline\",\"Flight_code\",\"Class\",\"Source\",\"Departure\",\"Total_stops\",\n",
    "        \"Arrival\",\"Destination\", \"Duration_in_hours\", \"Days_left\", \"Fare\"]\n",
    "dtf = dtf[cols]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "626b86c5-ee92-4bf3-a370-ef70c09b704f",
   "metadata": {},
   "source": [
    "Taking a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a048e3-750b-4f7d-9695-4d3b1ec55ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e87cce-67e5-41ad-95ba-7764a209a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edda10-feea-4223-9962-9da58ee55d0e",
   "metadata": {},
   "source": [
    "Examining the target feature - \"SalePrice\": Using a histogram, a KDE plot, and a box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36a525-2589-445b-ab91-7565b06e3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.Fare.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbd7fa-ae63-4600-8f9c-2d41f9f11d67",
   "metadata": {},
   "source": [
    "x: the flight fare \n",
    "y: the amount of flights of each fare range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dac59-6ff6-4575-a85c-fef2b0acea52",
   "metadata": {},
   "source": [
    "Exploring tickets fare:\n",
    "From the table above we learn that the minimum ticket fare is 1,307 and maximum is 143,019. There exists differnce in mean and median values as well. Let's visualize the price column using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5b799-bee2-49b4-a5b7-642c7f75c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(dtf.Fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14876d08-c873-47b6-85e3-53d490b20a0b",
   "metadata": {},
   "source": [
    "We can see that the data may contains outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7a8da-a940-430c-84da-62dd39daaace",
   "metadata": {},
   "source": [
    "Let's Examine outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9f140-293b-4ee0-a23d-8b309383fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(dtf.Fare, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f606d-613b-4cd5-915b-9ef4fe883067",
   "metadata": {},
   "source": [
    "A Fare outlier is acceptable because there are different ticket classes like - Economy, Premium Economy, Business and First class.\n",
    "Even though the mean is around 20000, we can see here that the median is approximately 14000.\n",
    "On the First graph, we can see that the dispersion seems to be composed by two gaussian curves. From 1,000 to 30,000 there is one peak, corresponding to the cheap tickets and the second peak from 40,000 to 80,000 corresponding to the expensive class tickets.\n",
    "We have decided not to remove the price outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8aca18-840d-4723-9a5e-5de2375a3441",
   "metadata": {},
   "source": [
    "Exploration of the data and understanding the relationships between the different features in the dataset.(todo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772cecdc-fa16-41e8-8d23-4acc822cc18e",
   "metadata": {},
   "source": [
    "Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c834d-b3c5-44fe-a286-006948139f83",
   "metadata": {},
   "source": [
    "Making sure there are no null values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc20a0d-b005-4629-9d8d-59b32431a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d711c6-d518-4267-b083-fb897a13a1f3",
   "metadata": {},
   "source": [
    "There are no missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a320011-166e-4124-a052-25d37cb763b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking duplicates\n",
    "dtf.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb094e-bf4e-47f9-b7de-2abb1c3d1619",
   "metadata": {},
   "source": [
    "There are 6722 duplicated rows. So let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c865a-2767-479e-b253-14d749885c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dtf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad04cc-6a37-4925-8d3d-2783b980f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the duplicates are gone\n",
    "dtf.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d7e8f-beea-42d4-91f9-2c8a30fd531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column  from 'Days_left' to 'Advance_purchase_days' for clearity\n",
    "dtf.rename(columns={'Days_left': 'Advance_days'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecedf1-30af-402a-afd7-24f3c5774fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distinct values of departure and arrival cloumns\n",
    "dtf['Departure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2888a-7d5f-464a-93d5-aa4fcb7f6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf['Arrival'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281afb79-2645-4549-9462-8cda7fa4b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the departure and arrival columns to time \n",
    "\n",
    "# Function to map departure time ranges to categories\n",
    "def map_departure_time_range(departure_time):\n",
    "    if 'Before 6 AM' in departure_time:\n",
    "        return 'Early morning'\n",
    "    elif '6 AM - 12 PM' in departure_time:\n",
    "        return 'morning'\n",
    "    elif '12 PM - 6 PM' in departure_time:\n",
    "        return 'noon'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# Apply the function to the columns\n",
    "dtf['Departure'] = dtf['Departure'].apply(map_departure_time_range)\n",
    "dtf['Arrival'] = dtf['Arrival'].apply(map_departure_time_range)\n",
    "\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd25a6e-58a1-49d6-9695-d006375ba407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"Date_of_journey\" column to datetime format\n",
    "dtf['Date_of_journey'] = pd.to_datetime(dtf['Date_of_journey'])\n",
    "\n",
    "# Extract the month from the dates\n",
    "dtf['Month'] = dtf['Date_of_journey'].dt.month\n",
    "\n",
    "# Group the flights by month and count the number of flights in each month\n",
    "dtf.groupby('Month').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f300b-787e-4712-a9ec-4cb24702cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Month_ = pd.to_datetime(dtf.Date_of_journey.values).month\n",
    "pd.Series(Month_.value_counts(normalize = True).values,index=[\"Feb\",\"Jan\",\"Mar\"]).\\\n",
    "    plot(kind=\"barh\",title=\"Flights monthly variations\", figsize = [2,2], xlabel = \"Relative frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0dd5bd-a327-4185-924a-8b2a6c82ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.Journey_day.value_counts(normalize = True, ascending = True).plot(kind=\"barh\",\n",
    " title = \"Flights daily variations\",xlabel = \"Relative frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484ac99-5b74-47d1-9bab-a70427924ed0",
   "metadata": {},
   "source": [
    "Given the daily variations observed in the dataset, with flights evenly distributed across the seven weekdays. We want to make sure that the frequencies of values in our training and test sets reflect the daily variations reported in the original dataset. Therefore, we'll apply a stratified split based on this feature later when we split the data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3e126-d59c-4f0b-96c6-1a8f47838979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will create a histogram for each categorical attribute\n",
    "\n",
    "# Define the names of categorical columns to remove\n",
    "columns_to_remove = [\"Date_of_journey\", \"Flight_code\"]\n",
    "\n",
    "# Define the desired order of categorical columns\n",
    "desired_order = [\"Airline\", \"Departure\", \"Arrival\", \"Total_stops\", \"Journey_day\", \"Source\", \"Destination\", \"Class\"]\n",
    "\n",
    "# Filter categorical columns based on the condition and desired order\n",
    "categorical_columns_filtered = [c for c in desired_order if c not in columns_to_remove]\n",
    "                                \n",
    "n = len(categorical_columns_filtered)\n",
    "cols = 2\n",
    "max_bars = 8\n",
    "\n",
    "rows = (n // cols) + (1 if n % cols != 0 else 0)\n",
    "\n",
    "#generate a figures grid:\n",
    "fig, axes = plt.subplots(rows,cols,figsize=(cols*5,rows*5))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i,column in enumerate(categorical_columns_filtered):\n",
    "    #calculate the current place on the grid\n",
    "    r=int(i/cols)\n",
    "    c=i%cols\n",
    "    \n",
    "    #create the \"value counts\" for the first <max_bars> categories:\n",
    "    u=min(dtf[column].nunique(),max_bars)\n",
    "    vc = dtf[column].value_counts()[:u]\n",
    "    \n",
    "    # plot a bar chart using Pandas\n",
    "    vc.plot(kind='bar',ax=axes[r,c],title=column)\n",
    "    axes[r, c].set_xlabel('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2f29f-d78b-410a-b614-27c62bf9c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will create a histogram for each numeric attribute\n",
    "dtf.Duration_in_hours.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d098bc-706d-4af0-bcde-09e41739bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.Advance_days.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569b9ec-c5d6-4045-a1d4-b2005ebe0426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dtf.groupby(\"Destination\")[\"Arrival\"].value_counts()\n",
    "data.head(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53886516-9cbb-4e83-9e70-c6baf205d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the violin plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(x='Class', y='Fare', data=dtf)\n",
    "plt.title('Price Distribution of the flights for each number of stops')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063f001-65b5-4ff5-9a9e-73b177f3c98b",
   "metadata": {},
   "source": [
    "By using the violin plot we can learn about the distribution of the fligh prices in India.\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dba8cc-0e61-4608-98ef-239099fc7595",
   "metadata": {},
   "source": [
    "Examining Correlations to the target feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e853e-df35-4c6e-ab65-40cae30d0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = dtf.dtypes[(dtf.dtypes==\"float64\") | (dtf.dtypes==\"int64\")].index.tolist()\n",
    "numeric_columns = dtf[numeric_columns]\n",
    "dtf_corr = numeric_columns.corr(method=\"pearson\").loc[[\"Fare\"]]\n",
    "fig, ax = plt.subplots(figsize=(15,2))\n",
    "\n",
    "sns.heatmap(dtf_corr, annot=True, fmt='.2f', cmap=\"YlGnBu\", cbar=True, linewidths=0.5,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09495239-7477-48ba-b760-606226cf6110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a469cc5-d6f7-47a0-82f8-7eacd53ae982",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7147348-19b7-41f0-b4d0-10c73aa8aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split the dataset into features and target variables. the target variable is the proce, and all the others are the features.\n",
    "x = dtf.drop([\"fare\"], axis=1)\n",
    "y = dtf[\"fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4e6a2-08fc-46fc-9700-a57ac08103a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
